# MCP 智能化问答应用 - 启动说明

## 🚀 新功能特性

### 模型选择功能
现在用户可以自由选择使用本地模型或云端模型，不再受限于自动选择：

1. **🤖 自动选择**（默认）：系统智能判断，优先使用本地模型，失败时自动降级到云端模型
2. **🏠 本地模型**：强制使用本地的 GGUF 模型（qwen2-1.5b-instruct）
3. **☁️ 云端模型**：强制使用 API易 的云端模型，可选择：
   - 🚀 DeepSeek R1（默认）
   - 💬 DeepSeek Chat
   - 🤖 GPT-4o Mini

## 🛠️ 环境准备

### 1. 安装依赖

```bash
# 创建虚拟环境
python3 -m venv .venv
source .venv/bin/activate  # macOS/Linux
# .venv\Scripts\activate  # Windows

# 安装依赖
pip install -r requirements.txt
```

**重要**：如果要使用本地模型，需要安装 `llama-cpp-python`：
```bash
pip install llama-cpp-python
```

### 2. 配置环境变量

创建 `.env` 文件：
```bash
# 本地模型配置
GGUF_MODEL_PATH=/Users/sws/DB-GPT/qwen2-1_5b-instruct-q4_k_m.gguf

# 云端模型配置（API易）
OPENAI_API_KEY=your-api-key
OPENAI_BASE_URL=https://api.apiyi.com/v1
OPENAI_MODEL=deepseek-r1

# 数据库配置
HOSPITAL_DB_URL=mysql+pymysql://root:password@127.0.0.1:3306/hospital_db
WAREHOUSE_DB_URL=mysql+pymysql://root:password@127.0.0.1:3306/warehouse_db
```

### 3. 启动数据库

```bash
# 启动 MySQL 和 PostgreSQL 容器
docker compose up -d

# 等待容器启动完成（约 30 秒）
```

### 4. 启动应用

```bash
# 启动 FastAPI 应用
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

## 🎯 使用指南

### 前端界面操作

1. **访问应用**：打开浏览器访问 http://localhost:8000

2. **模型选择**：
   - 在左侧控制面板找到"模型选择"区域
   - 选择模型类型：自动选择、本地模型、云端模型
   - 如果选择云端模型，可以进一步选择具体的模型

3. **模型状态检测**：
   - 点击"测试模型"按钮检测本地和云端模型的可用性
   - 查看模型状态指示器

4. **开始使用**：
   - 选择数据库（医疗/仓储）
   - 选择用户角色
   - 输入问题开始智能问答

### API 接口使用

#### 1. 获取模型状态
```bash
GET /api/models/status
```

#### 2. 切换模型
```bash
# 切换到本地模型
POST /api/models/switch
{
    "model_type": "local"
}

# 切换到云端模型
POST /api/models/switch
{
    "model_type": "cloud",
    "model_name": "deepseek-r1"
}
```

#### 3. 智能问答（支持模型选择）
```bash
POST /api/chat
{
    "user_id": "D101",
    "question": "查询所有心内科的医生信息",
    "model_type": "cloud",  # auto, local, cloud
    "cloud_model": "deepseek-r1"  # 可选，指定云端模型
}
```

## 🔧 故障排除

### 本地模型问题

1. **llama-cpp-python 未安装**
   ```bash
   pip install llama-cpp-python
   ```

2. **模型文件不存在**
   - 检查 `GGUF_MODEL_PATH` 配置
   - 确保模型文件路径正确

3. **模型加载失败**
   - 检查模型文件是否损坏
   - 尝试重新下载模型文件
   - 使用"测试模型"功能重新加载

### 云端模型问题

1. **API Key 无效**
   - 检查 `.env` 文件中的 `OPENAI_API_KEY`
   - 确认 API易 账户状态

2. **模型不可用**
   - 检查 `OPENAI_BASE_URL` 配置
   - 确认选择的模型在 API易 中可用

### 数据库连接问题

1. **MySQL 连接失败**
   ```bash
   # 检查容器状态
   docker ps
   
   # 查看容器日志
   docker logs mysql_hospital
   ```

2. **PostgreSQL 连接失败**
   ```bash
   # 查看容器日志
   docker logs postgres_warehouse
   ```

## 📊 性能优化建议

### 本地模型
- 使用 SSD 存储模型文件
- 调整 `n_threads` 参数（在 `local_client.py` 中）
- 考虑使用量化模型减少内存占用

### 云端模型
- 根据需求选择合适的模型
- DeepSeek R1：适合复杂推理任务
- DeepSeek Chat：适合对话和问答
- GPT-4o Mini：平衡性能和成本

## 🔮 未来规划

- [ ] 支持更多本地模型格式
- [ ] 模型性能监控和统计
- [ ] 批量处理优化
- [ ] 模型缓存机制
- [ ] 多模型并行处理

## 📞 技术支持

如果遇到问题，请：

1. 检查应用日志
2. 使用"测试模型"功能诊断
3. 查看 Docker 容器状态
4. 确认环境变量配置

---

**注意**：首次启动时，系统会自动检测模型可用性。如果本地模型不可用，系统会自动使用云端模型，确保基本功能正常运行。
